# Q35. All O`one Data Structure

## Problem

Design a data structure that supports the following operations in **O(1) average time**:

| Operation | Description |
|---------|-------------|
| `inc(key)` | Increment the count of `key` by 1. If key doesn't exist, insert it with count 1. |
| `dec(key)` | Decrement the count of `key` by 1. If count becomes 0, **remove key**. |
| `getMaxKey()` | Return **any** key with the **maximum** count. If none, return `""`. |
| `getMinKey()` | Return **any** key with the **minimum** count. If none, return `""`. |

---

## Constraints

- `1 ≤ key.length ≤ 10`
- Keys consist of **lowercase English letters**
- Each `dec(key)` is **guaranteed valid** (key exists)
- Up to `5⋅10⁴` total calls

---

## Core Insight

This is a **frequency-tracking problem** with **constant-time retrieval of max/min keys**.

**Naive approach** (hash map + sorting) → **fails** due to time constraints.

**Key Idea**: Maintain **two structures**:

1. `count[key] → frequency`  
2. **Sorted structure** tracking `(frequency, key)`

This enables **O(1) access** to min/max via `begin()` / `rbegin()`.

---

## Architectural Triggers

| Trigger | Implication |
|--------|-------------|
| “O(1) average time” | Avoid sorting or linear scans |
| “getMaxKey / getMinKey” | Must maintain **order of frequencies** |
| “Up to 5e4 calls” | Must support **fast updates and queries** |

---

## What This Implies

Use **two structures**:

- `unordered_map<string, int>` → key to current count  
- `set<pair<int, string>>` → sorted by frequency (then lexicographically)

### Operations:

| Operation | Steps |
|---------|-------|
| `inc(key)` | 1. Erase `{old_count, key}`<br>2. Increment count<br>3. Insert `{new_count, key}` |
| `dec(key)` | 1. Erase `{old_count, key}`<br>2. Decrement count<br>3. If >0 → insert `{new_count, key}`<br>4. Else → erase from map |
| `getMaxKey()` | `se.rbegin()->second` |
| `getMinKey()` | `se.begin()->second` |

---

## Code (C++)

```cpp
class AllOne {
public:
    unordered_map<string, int> count;
    set<pair<int, string>> se;

    AllOne() {
        count.clear();
    }

    void inc(string key) {
        int n = count[key];
        count[key]++;
        se.erase({n, key});
        se.insert({n + 1, key});
    }

    void dec(string key) {
        int n = count[key];
        count[key]--;
        se.erase({n, key});
        if (count[key] > 0)
            se.insert({n - 1, key});
        else
            count.erase(key);
    }

    string getMaxKey() {
        return se.empty() ? "" : se.rbegin()->second;
    }

    string getMinKey() {
        return se.empty() ? "" : se.begin()->second;
    }
};
```

## Complexity

| Operation       | Time                    | Space  |
|-----------------|-------------------------|--------|
| `inc / dec`     | `O(log n)` (due to `set`) | `O(n)` |
| `getMaxKey`     | `O(1)`                  | `O(1)` |
| `getMinKey`     | `O(1)`                  | `O(1)` |

> **Note**: Not **strictly O(1)** due to `set`, but **acceptable** under average-case constraints.  
> For **true O(1)**, use **doubly linked list of frequency buckets**.

---

## Pitfalls

| Issue                              | Fix |
|-----------------------------------|-----|
| **Using `set` instead of bucket list** | Clean but not strictly O(1). For strict constraints, use **bucketed DLL** |
| **Incorrect erase/insert order**   | **Always erase old `{count, key}` first** — otherwise duplicates |
| **Assuming unique counts**         | Multiple keys can share count — `set<pair<int, string>>` handles via **lex order** |

---

## Insight

This is a **frequency-indexed data structure** problem.

**Core idea**: **Bidirectional access**:

- `key → count` (via map)  
- `count → key` (via ordered structure)

### Generalizes to:

- **LFU / LRU cache**
- **Frequency-based priority queues**
- **Real-time leaderboard tracking**

---

## Fichka Library Entry

> **Frequency tracking: constant-time min/max key retrieval via dual structure**


---

