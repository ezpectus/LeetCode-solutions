# 🧮 LeetCode 3510 — Minimum Pair Removal to Sort Array II

## 📜 Problem Summary

You're given an integer array `nums`. You can repeatedly perform the following operation:

- Select the **adjacent pair with the minimum sum**. If multiple such pairs exist, choose the **leftmost**.
- Replace the pair with their sum.

Return the **minimum number of operations** needed to make the array **non-decreasing**.

---

## 🧠 Core Insight

This isn’t a brute-force simulation — it’s a **priority-driven mutation system**.

The array isn’t just a list of numbers. It’s a **linked structure** where each mutation affects local order and global monotonicity. You’re not scanning — you’re evolving.

### 🔍 How the problem forces this architecture

The task description gives you no choice:

- **“Select the adjacent pair with the minimum sum”**  
  → You need fast access to all adjacent pairs and their sums.  
  → A `SortedSet<(sum, index)>` gives you priority selection with index-based tie-breaking.

- **“If multiple such pairs exist, choose the leftmost”**  
  → You must preserve adjacency and index order.  
  → That rules out heaps without index tracking, and any approach that rebuilds the array.

- **“Replace the pair with their sum”**  
  → This is not a value update — it’s a structural mutation.  
  → You remove one node and rewire its neighbors.  
  → Rebuilding the array breaks continuity and invalidates pair tracking.

- **Goal: make the array non-decreasing**  
  → You need to track violations like `values[i] > values[i+1]`  
  → Scanning the array after each mutation is too slow.  
  → You need a live counter: `brokenCount`.

### 🧱 What this implies

- You need `values[]` as a long array to avoid overflow
- You need `prev[]` and `next[]` to simulate links and preserve adjacency
- You need `pairSet` to always pick the correct pair
- You need `brokenCount` to know when to stop

> The problem doesn’t just allow this architecture — it demands it.
> Every line of the description pushes you toward a mutation engine with indexed memory and priority compression.

---

## 🔧 Architectural Strategy

### Core Structures

- `values[]`: long copy of `nums` to avoid overflow during merges
- `prev[]`, `next[]`: simulate a double-linked list using index arrays
- `pairSet`: `SortedSet<(sum, leftIndex)>` — tracks all adjacent pairs by sum
- `brokenCount`: number of adjacent violations (`values[i] > values[i+1]`)
- `operations`: total number of merges performed

### Initialization

1. Copy `nums` into `values[]` as `long`
2. Build `prev[]` and `next[]` links
3. Count initial violations → `brokenCount`
4. Insert all adjacent pairs into `pairSet` by `(values[i] + values[i+1], i)`

---

## 🔁 Mutation Loop

While `brokenCount > 0`:

1. **Extract** the leftmost pair with minimum sum from `pairSet`
2. **Merge** `values[left] += values[right]`
3. **Update links**:
   - `next[left] = next[right]`
   - `prev[next[right]] = left`
4. **Update `brokenCount`**:
   - Remove violation if `values[left] > values[right]`
   - Check neighbors (`prev[left]`, `next[right]`) for new or resolved violations
5. **Update `pairSet`**:
   - Remove outdated pairs: `(prev, left)`, `(right, next)`
   - Insert new pairs: `(prev, left)`, `(left, next)`
6. **Increment `operations`**

> Only local neighbors are touched. No full scans. No index drift. No rebuilds.

---
## 🚀 C# Implementation

```csharp
public class Solution {
    public int MinimumPairRemoval(int[] nums) {
        int n = nums.Length;
        long[] values = new long[n];
        for (int i = 0; i < n; i++) values[i] = nums[i];

        var pairSet = new SortedSet<(long sum, int leftIndex)>();
        int[] next = new int[n];
        int[] prev = new int[n];
        for (int i = 0; i < n; i++) {
            next[i] = i + 1;
            prev[i] = i - 1;
        }

        int brokenCount = 0;
        for (int i = 0; i < n - 1; i++) {
            if (values[i] > values[i + 1]) brokenCount++;
            pairSet.Add((values[i] + values[i + 1], i));
        }

        int operations = 0;
        while (brokenCount > 0) {
            var (minSum, left) = pairSet.Min;
            pairSet.Remove(pairSet.Min);

            int right = next[left];
            int leftNeighbor = prev[left];
            int rightNeighbor = next[right];

            // remove broken pair
            if (values[left] > values[right]) brokenCount--;

            // update left neighbor
            if (leftNeighbor >= 0) {
                if (values[leftNeighbor] > values[left] && values[leftNeighbor] <= values[left] + values[right]) brokenCount--;
                else if (values[leftNeighbor] <= values[left] && values[leftNeighbor] > values[left] + values[right]) brokenCount++;
            }

            // update right neighbor
            if (rightNeighbor < n) {
                if (values[rightNeighbor] >= values[right] && values[rightNeighbor] < values[left] + values[right]) brokenCount++;
                else if (values[rightNeighbor] < values[right] && values[rightNeighbor] >= values[left] + values[right]) brokenCount--;
            }

            // update pairSet
            if (leftNeighbor >= 0) {
                pairSet.Remove((values[leftNeighbor] + values[left], leftNeighbor));
                pairSet.Add((values[leftNeighbor] + values[left] + values[right], leftNeighbor));
            }

            if (rightNeighbor < n) {
                pairSet.Remove((values[right] + values[rightNeighbor], right));
                pairSet.Add((values[left] + values[right] + values[rightNeighbor], left));
                prev[rightNeighbor] = left;
            }

            next[left] = rightNeighbor;
            values[left] += values[right];
            operations++;
        }

        return operations;
    }
}
```
---

## ⏱️ Time and Space Complexity

| Metric       | Value         | Explanation                                      |
|--------------|---------------|--------------------------------------------------|
| Time         | O(n log n)    | Each pair insertion/removal in `SortedSet` is log n, and we do at most n merges |
| Space        | O(n)          | Arrays `values`, `prev`, `next`, and `pairSet` all scale linearly |

---

---

## ✅ Why This Works

- **SortedSet** guarantees leftmost minimum selection
- **prev/next** preserve structural integrity across merges
- **brokenCount** gives constant-time termination check
- **values[]** avoids overflow and keeps mutation atomic
- **Locality** ensures performance: only 2–4 neighbors touched per step

---

## 🧱 Engineering Takeaways

- Mutation chains must preserve structure — don’t rebuild, just patch
- Priority selection must be stable — use index to break ties
- Monotonicity is a global invariant — track it explicitly
- Overflow is silent — use `long` early
- Every mutation is local — optimize for locality, not global scans

> This is not a loop — it’s a controlled collapse system with indexed memory.

---

## 🧩 Generalization Pattern

This pattern applies to:

- Adjacent pair compression with priority
- Greedy mutation under global constraints
- Indexed structural simulation
- Stream reduction with monotonicity enforcement

> You don’t simulate blindly — you evolve the structure with awareness.


---

## 🧠 Final Insight

The core idea is simple:  
**You don’t simulate the array — you simulate its structure.**

This problem forces you to:

- Track adjacency without rebuilding
- Prioritize merges without ambiguity
- Maintain monotonicity without rescanning

The condition that breaks naive approaches is:  
> “If multiple minimum-sum pairs exist, choose the leftmost.”

This means:
- You can’t just scan for minimums — you need **stable priority with index tie-breaking**
- You can’t rebuild the array — you need **linked structure mutation**
- You can’t recheck monotonicity every time — you need **live violation tracking**

---

## 🧱 Why Other Approaches Fail

- **Naive simulation**: too slow (O(n²)) and loses index stability
- **Greedy merge without structure**: breaks tie-breaking and mutation locality
- **Heap without links**: can't update neighbors correctly

---

## ✅ Why This Approach Wins

- It compresses mutation chains using indexed memory
- It preserves adjacency and order via `prev[]` and `next[]`
- It guarantees correctness through priority and locality
- It scales to 10⁵ elements without breaking

> This is not a sorting problem — it’s a structural collapse engine with monotonicity constraints.


---
