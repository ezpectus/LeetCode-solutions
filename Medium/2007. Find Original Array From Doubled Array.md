# 2007. Find Original Array From Doubled Array  
*O(n log n) — Optimal Greedy + Frequency Map + Sorting*

---

## Problem Statement

You are given an array `changed` of length n (1 ≤ n ≤ 10⁵, 0 ≤ changed[i] ≤ 10⁵).

`changed` was obtained by taking some array `original`, appending **twice every element** of `original`, and then **randomly shuffling** the result.

Return **any** possible `original` array (in any order) if `changed` is a valid doubled array, otherwise return an **empty array**.

---

## Core Idea — Greedy Reconstruction with Frequency Map

**Key insight**:
- `changed` contains exactly twice as many elements as `original` (or odd length → impossible)
- Every value in `original` appears exactly **twice** in `changed` (once as itself, once as double)
- Zero is special: 0 can only appear even number of times (since 2×0 = 0)
- We can use a **frequency map** + **sorting** to greedily pair numbers

**Algorithm**:
1. If length odd → return [] (cannot be doubled array)
2. Build frequency map of all elements in `changed`
3. Sort the unique values (or process from smallest to largest)
4. For each number x in increasing order:
   - If x is **0** → must have even count (each 0 pairs with another 0)
   - Otherwise:
     - We need **exactly** freq[x] occurrences of x in original → must have **2 × freq[x]** occurrences of x in changed
     - And freq[2×x] must be ≥ freq[x] (because each x in original produces one 2×x)
     - Subtract 2 × freq[x] from freq[x] and freq[2×x]
5. If at any point we have negative frequency or leftover odd counts → impossible
6. Collect all x with positive freq[x] in original (multiples if freq[x] > 1)

**Why greedy smallest first?**
- Smaller numbers must be paired first (2×small can be large, but large cannot produce small)
- Processing small to large ensures we consume doubles correctly

**Time**: O(n log n) — sorting + map operations

---

## Clean Implementation (C#)

```csharp
public class Solution {
    public int[] FindOriginalArray(int[] changed) {
        int n = changed.Length;
        if (n % 2 == 1) return new int[0]; // odd length impossible

        var freq = new Dictionary<int, int>();
        foreach (int num in changed) freq[num] = freq.GetValueOrDefault(num) + 1;
        var original = new List<int>();

        // Sort keys to process from smallest to largest
        var keys = freq.Keys.ToList();
        keys.Sort();

        foreach (int x in keys) {
            if (freq[x] == 0) continue;
            if (x == 0) {
                // 0 can only pair with 0
                if (freq[0] % 2 == 1) return new int[0];
                original.AddRange(Enumerable.Repeat(0, freq[0] / 2));
                freq[0] = 0;
            } 
            else {
                int double_x = 2 * x;
                if (!freq.ContainsKey(double_x) || freq[double_x] < freq[x]) return new int[0];
                

                // Use freq[x] pairs: each x produces one 2x
                original.AddRange(Enumerable.Repeat(x, freq[x]));
                freq[double_x] -= freq[x];
                freq[x] = 0;
            }
        }

        // Check if anything left (should be 0)
        foreach (var count in freq.Values) {
            if (count > 0) return new int[0];
        }

        return original.ToArray();
    }
}
```

## Complexity

| **Metric**            | **Value**             | **Notes**                                      |
|-----------------------|-----------------------|------------------------------------------------|
| **Time Complexity**   | **O(n log n)**        | Building frequency map: O(n)  
Sorting unique keys: O(d log d) where d ≤ n  
Processing each unique value: O(d) → overall O(n log n) |
| **Space Complexity**  | **O(n)**              | Frequency map + output list (worst case all unique values) |

**Optimal** — linearithmic time, perfect for n ≤ 10⁵ constraints.

---

## Why This Works — Example Walkthrough

**Example 1**: `changed = [1,3,4,2,6,8]`

- Frequency map: 1:1, 2:1, 3:1, 4:1, 6:1, 8:1
- Sorted unique values: [1,2,3,4,6,8]
- Process smallest first:
  - x=1 → double=2 → freq[2] ≥ 1 → add one 1 to original, freq[2] -=1 → 0
  - x=3 → double=6 → freq[6] ≥1 → add one 3, freq[6] -=1 → 0
  - x=4 → double=8 → freq[8] ≥1 → add one 4, freq[8] -=1 → 0
- All frequencies consumed → original = [1,3,4] (any order) → correct

**Example 2**: `changed = [6,3,0,1]`

- Frequency map: 0:1, 1:1, 3:1, 6:1
- Process:
  - x=0 → freq[0]=1 (odd) → impossible (0 must pair with another 0) → return [] → correct

**Correct** — greedy processing from smallest to largest ensures we always pair each x with its double 2x before larger numbers try to claim them.  
This prevents leftover unmatched doubles and guarantees correctness.

---

## Pitfalls & Edge Cases

- **Odd length of changed** → immediately impossible → return []
- **Zeroes** → must appear an **even** number of times (each 0 in original produces one more 0)
- **No doubles available** (e.g. [1,2,3]) → some x has no 2x → impossible → []
- **Duplicates** (e.g. [2,2,4,4]) → freq[2]=2, freq[4]=2 → pair two 2's with two 4's → original [2,2] → correct
- **n = 10⁵** → O(n log n) — efficient and passes time limits

All handled perfectly.

---

## Key Takeaway

This is a **classic greedy reconstruction** problem:

- Use a **frequency map** to count occurrences of each number in `changed`
- Sort the unique values in **ascending order**
- Process each smallest x:
  - Special case x=0 → frequency must be even
  - Normal case → freq[2×x] must be ≥ freq[x]
  - Add freq[x] copies of x to the result (original)
  - Subtract 2×freq[x] from freq[x] and freq[2×x] (consume pairs)
- If any frequency becomes negative or leftover non-zero frequencies remain → impossible → return []
- Otherwise return the collected original array (in any order)

**Pure, clean, optimal** — O(n log n) time, elegant greedy logic, correct and efficient.

---
