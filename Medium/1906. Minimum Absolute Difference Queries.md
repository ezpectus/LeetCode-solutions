# 1906. Minimum Absolute Difference Queries  
*O(n + q × 100) — Optimal Precomputation + Binary Search per Value*

---

## Problem Statement

You are given an integer array `nums` (2 ≤ n ≤ 10⁵, 1 ≤ nums[i] ≤ 100)  
and `queries` where each query is [li, ri] (0 ≤ li < ri < n, up to 2×10⁴ queries).

For each query [li, ri], compute the **minimum absolute difference** in the subarray `nums[li..ri]`:

- min |nums[a] - nums[b]| over li ≤ a < b ≤ ri where nums[a] ≠ nums[b]
- If all elements in the subarray are equal → return -1

Return an array `ans` where `ans[i]` is the answer for the i-th query.

---

## Core Idea — Precompute Positions + Binary Search per Value

**Key insight**:
- nums[i] ≤ 100 → only **100 possible values** (1 to 100)
- For a range [li, ri], the min diff is the smallest |x - y| > 0 between **distinct values** present in the range
- So → collect all **distinct values** that appear at least once in [li, ri]
- Sort them → find the minimum difference between consecutive values
- If ≤ 1 distinct value → -1

**How to find distinct values in range quickly?**
- Precompute for each value v = 1 to 100: **sorted list** of all indices where nums[i] == v
- For each query [li, ri]:
  - For each v = 1 to 100:
    - Use **binary search** (lower bound) on the sorted positions of v
    - If there is any index ≥ li and ≤ ri → v appears in the range → add v
  - Sort the collected distinct values (≤ 100 numbers)
  - Find min consecutive difference (if ≥ 2 values)

**Time**:
- Preprocessing: O(n log n) total (sorting 100 lists, each up to n elements)
- Per query: 100 × log n (binary search) + sort 100 values → O(100 log n)
- Total: O(n log n + q × 100 log n) ≈ 10⁵ log 10⁵ + 2×10⁴ × 100 × 17 ≈ 3.4M operations — very fast

---

## Clean Implementation (C#)

```csharp
public class Solution {
    public int[] MinDifference(int[] nums, int[][] queries) {
        int n = nums.Length;
        int q = queries.Length;

        // Precompute sorted positions for each value 1..100
        List<int>[] positions = new List<int>[101];
        for (int v = 0; v <= 100; v++)  positions[v] = new List<int>();
        for (int i = 0; i < n; i++)  positions[nums[i]].Add(i);
        
        int[] ans = new int[q];
        for (int qi = 0; qi < q; qi++) {
            int left = queries[qi][0];
            int right = queries[qi][1];

            // Collect all distinct values that appear in [left, right]
            List<int> vals = new List<int>();

            for (int v = 1; v <= 100; v++){
                var pos = positions[v];
                if (pos.Count == 0) continue;

                // Binary search for first index >= left
                int idx = pos.BinarySearch(left);
                if (idx < 0) idx = ~idx;

                // If found any index in [left, right]
                if (idx < pos.Count && pos[idx] <= right) vals.Add(v);
                
            }

            if (vals.Count <= 1)  {
                ans[qi] = -1;
                continue;
            }

            vals.Sort();
            int minD = int.MaxValue;
            for (int i = 1; i < vals.Count; i++) {
                minD = Math.Min(minD, vals[i] - vals[i - 1]);
            }

            ans[qi] = minD;
        }

        return ans;
    }
}
```

## Complexity

| **Metric**            | **Value**                             | **Notes**                                                                 |
|-----------------------|---------------------------------------|---------------------------------------------------------------------------|
| **Time Complexity**   | **O(n log n + q × 100 × log n)**      | Preprocessing: sorting 100 position lists → O(n log n)                    |
|                       |                                       | Per query: 100 binary searches (log n each) + sorting up to 100 values   |
| **Space Complexity**  | **O(n)**                              | Total size of all position lists = O(n)                                   |

**Optimal** — exploits the tiny value range (1..100) to achieve very fast per-query checks (~3.4M operations total for max constraints).

---

## Why This Works — Example Walkthrough

**Example 1**: `nums = [1,3,4,8]`, `queries = [[0,1],[1,2],[2,3],[0,3]]`

- Precomputed positions:
  - 1 → [0]
  - 3 → [1]
  - 4 → [2]
  - 8 → [3]

- Query [0,1]: range contains 1,3 → sorted [1,3] → min diff = **2**
- Query [1,2]: 3,4 → diff = **1**
- Query [2,3]: 4,8 → diff = **4**
- Query [0,3]: 1,3,4,8 → min consecutive diff = **1** (3-4)

Output **[2,1,4,1]** → correct

**Correct** — for every query [li, ri], we collect all distinct values appearing in the range using binary search on pre-sorted position lists → sort the small list (≤ 100 values) → find the minimum difference between any two consecutive values.  
If ≤ 1 distinct value → return -1.

---

## Pitfalls & Edge Cases

- **All elements in range are equal** → only one distinct value → return **-1**
- **Query of length 2** → just |nums[li] - nums[ri]| if different, else -1
- **Value range 1..100** → only 100 lists to check per query → very efficient
- **n, q ≤ 10⁵** → 100 × log(10⁵) × 2×10⁴ ≈ 3.4 million operations → extremely fast
- **No distinct values** → impossible (n ≥ 2), but if all same → -1

All handled perfectly.

---

## Key Takeaway

This is a **beautifully efficient range distinct values** problem:

- Precompute for each possible value v (1 to 100): a **sorted list** of all indices where `nums[i] == v`
- For each query [li, ri]:
  - For v = 1 to 100: use **binary search** to check if any index lies in [li, ri] → collect v if yes
  - Sort the collected distinct values (at most 100)
  - Compute the minimum difference between any two consecutive values
  - If fewer than 2 distinct values → return -1

**Pure, clean, optimal** — leverages the extremely small value range (1..100) + binary search to answer each query in near-constant time.

---
